---
title: "Appendix II - R Code for Enhancing Patient Engagement in Preventative Care: A Field Experiment on the Effectiveness of Personalized and Generic Digital Outreach Strategies"
author: "Lynne Wang, Mridul Jain, Jesse Cox, and Tejasvi Kalakota"
date: "04/18/2025"
output:
  pdf_document:
    number_sections: yes
    latex_engine: xelatex
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(data.table)
library(sandwich)
library(lmtest)
library(dplyr)
library(ggplot2)
library(tidyr) 
library(data.table)
library(knitr)
library(lubridate)
library(data.table)
library(sandwich)
library(lmtest)
library(AER) 
library(ggplot2) 
library(patchwork)

knitr::opts_chunk$set(dpi = 300)
data <- fread('C:/Users/Samsung/OneDrive/MIDS/241/set 5 problems/data/anonimized_final_data.csv')
```

```{r load data, echo=TRUE, message=TRUE, warning=FALSE}
# Load and preview the first few rows of the data
# This gives a quick view of variables like variant_assignment, unsubscribed, opened, click, and visit
print(head(data))
d <- data
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Count the number of patients assigned to each variant group
# Helps confirm balance of randomization across control and treatment groups
data %>%
  count(variant_assignment)

# Summarize click behavior by treatment arm
# Outputs total clicks and average click rate per group
d %>%
  group_by(variant_assignment) %>%
  summarise(n = n(), clicks = sum(click, na.rm = TRUE), click_rate = mean(click, na.rm = TRUE))

```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Summarize key engagement outcomes by treatment group
# Includes counts of clicks, visits, and unsubscribes for plotting
summary_counts <- d %>%
  group_by(variant_assignment) %>%
  summarise(
    Clicked = sum(click),
    Visited = sum(visit),
    Unsubscribed = sum(unsubscribed)
  ) %>%
  pivot_longer(
    cols = c(Clicked, Visited, Unsubscribed),
    names_to = "Outcome",
    values_to = "Count"
  )

# Plot bar chart comparing counts of engagement metrics by variant group
# Visualizes Clicked, Visited, and Unsubscribed across Control, Placebo, and Treatment groups
ggplot(summary_counts, aes(x = variant_assignment, y = Count, fill = Outcome)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Engagement Metrics by Variant Assignment", x = "Variant Assignment", y = "Count") +
  theme_minimal()
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Filter data to include only treatment-related groups (excluding control)
# Used for comparing email open rates across different outreach strategies
data_subset_1 <- data %>%
  filter(variant_assignment %in% c("placebo", "treatment_generic", "treatment_personalized"))

# Estimate linear model to compare open rates across variant_assignment
# Robust standard errors account for heteroskedasticity
model_opened <- lm(opened ~ variant_assignment, data = data_subset_1)
robust_se <- coeftest(model_opened, vcov = vcovHC(model_opened, type = "HC1"))
print(robust_se)
```

```{r}
# Intention-to-treat analysis: calculate open rate and sample size per variant
# Used to assess compliance and attrition
itt_open <- data_subset_1 %>%
  group_by(variant_assignment) %>%
  summarise(open_rate = mean(opened == 1), count = n())
print(itt_open)
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Filter to just treatment_generic and treatment_personalized groups
# Fit model to compare unsubscribe rates between personalized and generic emails
data_subset_2 <- data %>%
  filter(variant_assignment %in% c("treatment_generic", "treatment_personalized"))

model_unsubscribed <- lm(unsubscribed ~ variant_assignment, data = data_subset_2)

# Output summary with robust standard errors (HC1)
coeftest(model_unsubscribed, vcov = vcovHC(model_unsubscribed, type = "HC1"))
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Filter to just treatment_generic and treatment_personalized groups
# Fit model to compare click rates between personalized and generic emails
data_subset_3 <- data %>%
  filter(variant_assignment %in% c("treatment_generic", "treatment_personalized"))

model_click <- lm(click ~ variant_assignment, data = data_subset_3)

# Output summary with robust standard errors (HC1)
coeftest(model_click, vcov = vcovHC(model_click, type = "HC1"))
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Filter to just control, treatment_generic and treatment_personalized groups
# Fit model to compare visit rates between personalized and generic emails

data_subset_4 <- data %>%
  filter(variant_assignment %in% c("control", "treatment_generic", "treatment_personalized"))

model_visit <- lm(visit ~ variant_assignment, data = data_subset_4)

# Output summary with robust standard errors (HC1)
coeftest(model_visit, vcov = vcovHC(model_visit, type = "HC1"))
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Add covariate for recency of healthcare interaction, and generate interaction term with treatment.
# Enables HTE analysis to see if treatment works differently for patients not recently seen.

today <- as.Date("2025-04-15")

d <- d %>%
  mutate(last_seen = ifelse(last_seen == "a while ago", '04/01/2024', last_seen))

d <- d %>%
  mutate(
    # Step 2: Convert from m/d/Y to Date
    last_seen_clean = mdy(last_seen),

    # Step 3: Compute days since seen
    days_since_seen = as.numeric(Sys.Date() - last_seen_clean),

    # Step 4: Define seen_recently as â‰¤ 365 days
    seen_recently = ifelse(days_since_seen <= 365, 1, 0)
  )
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Fit a model including an interaction between treatment assignment and not_seen_recently.
# Helps test whether timing of last engagement modifies treatment effects.

# Set 'not seen recently' (0) as the reference level
# Create a new variable: not_seen_recently
d$not_seen_recently <- as.numeric(d$seen_recently == 0)

# Filter out the placebo group
d_filtered <- d %>% filter(variant_assignment %in% c("control", "treatment_generic", "treatment_personalized"))

# Create a new variable: not_seen_recently
d_filtered$not_seen_recently <- as.numeric(d_filtered$seen_recently == 0)

# Fit the model using the new variable
model_HTE <- lm(visit ~ variant_assignment * not_seen_recently, data = d_filtered)
robust_se <- vcovHC(model_HTE, type = "HC1")
robust_results <- coeftest(model_HTE, vcov = robust_se)
print(robust_results)
```

```{r, echo=TRUE, message=TRUE, warning=FALSE}
# Simulate statistical power at different sample sizes for three effect sizes: 0.005, 0.01, 0.02.
# Helps visualize sensitivity of the study to detect effects under realistic assumptions.

set.seed(3)

power_test_t <- function(
  mean_control = 0.02, 
  mean_treat = 0.03, 
  sd_control = sqrt(0.02 * 0.98), 
  sd_treat = sqrt(0.02 * 0.98),
  number_per_condition = 40, 
  power_loops = 1000, 
  verbose = FALSE) { 
    p_values <- numeric(power_loops)  
    for (i in 1:power_loops) { 
        control_group <- rnorm(number_per_condition, mean = mean_control, sd = sd_control)
        treatment_group <- rnorm(number_per_condition, mean = mean_treat, sd = sd_treat)
        
        test_result <- t.test(control_group, treatment_group, var.equal = FALSE) 
        p_values[i] <- test_result$p.value
    }
      
    power_estimate <- mean(p_values < 0.05)
    return(list('p_values' = p_values, 'power' = power_estimate))
}
```

```{R, echo=TRUE, message=TRUE, warning=FALSE}
# Generate line plot showing how sample size impacts power for each effect size.
# A horizontal line at 0.8 indicates the standard threshold for acceptable power.

# Sample sizes
samples_per_condition <- c(100, 200, 300, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1500, 1750, 2000, 2500, 5000)

# Calculate power for treatment effects of +0.005, +0.01, +0.02
power_005 <- numeric(length(samples_per_condition))
power_01 <- numeric(length(samples_per_condition))
power_02 <- numeric(length(samples_per_condition))

for(i in seq_along(samples_per_condition)) {
  power_005[i] <- power_test_t(mean_control = 0.02, mean_treat = 0.025,
                                number_per_condition = samples_per_condition[i])$power
  power_01[i] <- power_test_t(mean_control = 0.02, mean_treat = 0.03,
                               number_per_condition = samples_per_condition[i])$power
  power_02[i] <- power_test_t(mean_control = 0.02, mean_treat = 0.04,
                               number_per_condition = samples_per_condition[i])$power
}

# Assemble power table
power_table <- data.frame(
  "Sample Size" = samples_per_condition,
  "ATE 0.005" = power_005,
  "ATE 0.01" = power_01,
  "ATE 0.02" = power_02
)

# Plot results
plot(samples_per_condition, power_005, type = "o", col = "red", lwd = 2, pch = 16, ylim = c(0, 1),
     xlab = "Sample Size per Condition", ylab = "Power", main = "Power Curves for ATEs of 0.005, 0.01, 0.02")
lines(samples_per_condition, power_01, col = "blue", lwd = 2, type = "o", pch = 17)
lines(samples_per_condition, power_02, col = "green", lwd = 2, type = "o", pch = 18)
abline(h = 0.8, col = "gray", lty = 2, lwd = 2)
legend("bottomright", legend = c("ATE = 0.005", "ATE = 0.01", "ATE = 0.02"),
       col = c("red", "blue", "green"), lwd = 2, pch = c(16, 17, 18))
```

